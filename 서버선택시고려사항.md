# 서버선택시고려사항 및 트레픽 관리

# 대욜량 트래픽 처리를 위한 6가지 방법
1. 서버의 수평적 확장과 로드 밸런싱 - 서버를 수평적으로 확장하고 로드 밸런싱을 추가하여 트래픽을 분산시킨다. (CPU추가, 램 추가, 서버 업그레이드 등등 네트워크 대역폭 늘리기)
2. 캐시 사용 - 캐시를 적용하여 반복적인 요청을 처리하는 데 피룡한 리소스를 줄일수 있다.
4. CDN(Content Delivery Network)사용 - CDN을 사용하여 콘텐츠를 여러 리전에 분산하여 물리적인 거리를 줄여서 데이터 요청에 대한 응답 속도를 향상 시킬 수 있다.
5. 데이터 베이스 최적화 - 인덱스 추가하거나 쿼리를 최적화 하여 데이터 초리 속도를 향상 시킬 수 있다.
6. DNS 캐싱 서버 사용 - DNS 캐싱 서버를 사용하여 DNS 조회 요청을 줄여 응답 시간을 단축 시킬수 있다.
7. 코드 최적화 -코드 최적화 하여 실행시간을 단축하면 처리할 수 있는 트래픽 양이 늘어어날 수 있다.
- https://jeounpar.tistory.com/29


## 관련 사이트
- https://velog.io/@wkdgus7113/%EC%84%9C%EB%B2%84%EA%B0%80-%EB%8C%80%EB%9F%89%EC%9D%98-%ED%8A%B8%EB%9E%98%ED%94%BD%EC%9D%84-%ED%95%B4%EA%B2%B0%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95-Scale-Out-%EB%8B%A4%EC%A4%91%EC%84%9C%EB%B2%84-jk063hwk
- (스프링 대용량 트래픽 처리) https://www.nextree.io/seupeuring-daeyongryang-teuraepig-ceori/
- (서버 병목현상) https://fastercapital.com/ko/content/%EC%84%9C%EB%B2%84-%EB%B3%91%EB%AA%A9-%ED%98%84%EC%83%81-%ED%92%80%EA%B8%B0--%EC%9B%B9%EC%82%AC%EC%9D%B4%ED%8A%B8-%EC%84%B1%EB%8A%A5-%ED%96%A5%EC%83%81.html
- (100만 동시 접속 관련) https://velog.io/@tilsong/Mass-Ticket-100%EB%A7%8C-%EB%8F%99%EC%8B%9C-%EC%A0%91%EC%86%8D%EC%9D%84-%EA%B2%AC%EB%8E%8C%EB%82%B4%EB%8A%94-%ED%8B%B0%EC%BC%93-%EC%98%88%EB%A7%A4-%ED%86%A0%EC%9D%B4-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8
- (네이버의 트래픽 처리) https://d2.naver.com/helloworld/6070967
- 

## 기본 배경
- 100KB 용량의 이미지를 10만명이 조회하면 대락 10GB의 트래픽이 발생(네이버페이지)하므로, 100번의 호출이면 10MB 정도.

### Thread 관리
- 스레드 개념 : 실행중인 한 프로그램(프로세스) 내에서 구분지어진 실행 단위
- CPU는 여러 스레드 단위로 스레드를 번갈아 가며 작업을 처리
- 스레드가 생성되면, 스레드는 필요한 메모리를 할당받아 처리하므로 스레드가 많아지면 스레드가 차지하는 메모리가 커져서 메모리가 부족해질 수 있다.
- 스레드가 많아지면 컨텍스트 스위칭(CPU에서 실행중이던 스레드가 다른 스레드로 바뀌는 것을 의미) 비용이 커진다. 컨텍스트 스위칭 비용이 컬지 것이므로 CPU의 시간을 소모하게 되고 더 나아가서는 CPU 에 오버헤닥 발생하여 성능이 저하 될 수 있습니다.

### Thread Pool?
- 스레드를 매번 생성한다면 매번 메모리를 사용하게 되므로 Thread Pool에 한번 생성한 스레드를 저장해놓는 방식으로 해당 문제를 보완할 수 있다.
- 스레드 풀은 '생성한 스레드를 보관하는 저장소'로서 이해하면됨. 스레드가 생성시 스레드 풀에 저장되고, 작업 처리 후 소멸되는 것이 아니라 스레드 풀에 남게되어 이후에 작업이 필요하면 해당 스레드를 재사용하여 작업을 처리
- 처리 과정
 1. 스레드 풀에 작업 처리 요청(Task Submitters)
 2. 작업요청이 작업 큐에 쌓인다(Task Queue)
 3. 작업 큐에 쌓인 작업들을 스레드 풀에 있는 스레드가 하나씩 맡아서 수행한다.(만약 처리할 스레드가 없다면 작업 큐에서 대기)
- 스레드 풀에서 '작업 큐'라는 큐를 도입하여 작업 처리 요청이 많아져도 작업 큐에서 대기하기 때문에 요청마낟 스레드의 개수를 늘리지 않고 슬데에ㅢ 전체 개수느는 일정하며 성능이 저하되지 않는다.

### Tomcat 설정(Tomcat Thread Pool)

- threads.min-spare : 톰캣 스레드 풀에 대기 상태로 있는 스레드 개수
- threads.max : 스레드 풀이 '동시에' 사용할 수 있는 최대 스레드 개수
- max-connections : Tomcat 서버가 '동시에 처리할 수 있는 최대 클라이언트 연결 수'
- accept-count : **max-connections 이상의 요청이 들어 왔을 때 사용하는 요청 대기열 큐의 사이즈** 만약 max-connections 이상의 연결 시도라서 요청 대기열 큐에 저장되는데, 요청 대기열 큐의 사이즈인 accept-count 보다도 연결 시도가 많아지면 연결을 거부한다.
- Java의 스레드 풀과 Tomcat의 스레드 풀의 차이는 '**accept-count**'와 관련이 있습니다.
- Java 스레드 풀의 Queue는 작업 큐로, 작업 요청이 들어오면 무조건 작업 큐를 거쳐서 스레드에 할당
- Tomcat에서 사용되는 Queue는 요청 대기열 큐로, 'max-connections 이상의 요청이 들어 왔을 때' 작업이 저장되게 됩니다.

```java
server:
  tomcat:
    accept-count: 5
    max-connections: 150
    threads:
      max: 50
      min-spare: 20

```
- min-spare: 20 - 기본적으로 스레드 풀에 대기 상태로 존재하는 스레드가 20개 있다.
- max: 50 - 스레드 풀이 동시에 사용할수 있는 초대 스레드 개수, 50개의 요청을 동시에 처리할 수 있다.
  만약 동시에 50개 요청이 오면, 대기 상태인 20개의 스레드를 제외하고 30개 스레드가 생성되어 50개의 요청을 동시 처리한다.
  TomcatConnector는 50개의 TCP Connection을 연결하고 있다.
- accept-count: 5 - 만약 100개의 요청이 오면, 최대 스레드 개수인 50개만큼 처리하고, 5개씩 큐에 저장
- max-connections: 150　－만약 200개의 요청이 오면, 150개의 요청이 수락되고 요청 대기여 큐 사이즈(accept-count)인 5만큼 요청이 수락되고, 나머지 45개의 요청은 거절된다.(이때, 요청 대기열 큐에 저장되는 작업들은 TCP Connection을 맺이 않고 있다.)

 
## 스레드 (https://velog.io/@devel_sujin/%EB%8F%99%EC%8B%9C-%EC%9A%94%EC%B2%AD-%EB%A9%80%ED%8B%B0-%EC%93%B0%EB%A0%88%EB%93%9C#%EC%98%81%ED%95%9C%EB%8B%98%EC%9D%98-%EA%BF%80%ED%8C%81)
- 프로세스는 프로그램을 실행. 스레드는 프로그램 실행 안에서 동작하는 것을 의미
- 애플리 케이션 코드 하나 하나 순차적으로 실행하는 것

- 참고 : https://ksh-coding.tistory.com/116


### 로드 밸런싱
- 서버에 가해지는 부하를 분산하는 것으로 사용자들의 트래픽을 여러 서버가 나누어 받도록 구성하며, 일반적으로 네트워크 장비인 스위치를 할당해 로드 밸런싱할 수 있다.

### 캐시(Cache)
- 트래픽 처리를 위한 또 다른 방법으로근 캐시가 있다.캐시를 쉽게 설명하면 '비용이 큰 작업의 결고를 어딘가에 저장하여 비용이 작은 작업으로 동일한 효과를 내는것'
- 캐시를 이용하면 매번 요청이 들어올 때마다 비용이 큰 작업을 다시 수행할 필요 없이 미리 저장된 결과로 응답하면 된다.

- ![image](https://github.com/minya8703/WebHook/assets/97384342/8f9e8d82-ab7b-45f1-8712-8215b0d72d7e)
- https://webhosting.gabia.com/container/service
- 가비아에서 고려사항은 동시허용 접속수30conn을 넘을것인가 고려해보기. 

  ## 스프링에서 대용량 트래픽 처리
 ### 1. 대용량 트래픽 장애의 발생 원인
 - 사용자가 많아질 수록 서버에는  HTTP request가 발생한다. Request가 많아 졌다는 것은 트래픽이 높아졌다는 의미
 - Request는 Queue를 통하여 Thread pool에 할당되게 되는데 Thread pool size를 초과하는 요청은 큐에서 대기한다.
 - Thread의 개수는 무한하지 않으모르 시스템에 할당된 성능에 따라 제한되므로, Thread pool size를 초과하는  대랑의 트래픽이 지속적으로 발생하면 서버의 지연시간은 기하급술적으로 증가하게 된다. 이 현상을 Thread pool hell이라 한다.

### 2. 트래픽의 종류
#### Unicast
- Unicast는 일대일 통신 PC가 서버로 파일을 전송할 때 두 장치는 유니캐스트 통신을 사용
#### Multicast
- Multicast는 일대다 통신(송신기1대 - 수신기 여러대)
- 비디오 스트리밍을 예로 들수 있고, Multicast트래픽은 많은 차지에 보낼 수 있지만, 네트워크 내 모든 장치로 보낼 수는 없다. 패킷을 네트워크의 일부 선택된 스테이션에만 보낸다. 이메일 전송, 멀티미읻 전송 등이 있다.UDP전송 프로토콜을 사용.
- 테이터를 여러 사람에게 보내려면 유니캐스트를 사용할 때 많은 대역폭을 낭비하지만 멀티캐스팅은 대역폭을 보다 효율적으로 활용한다.
- 대규모 네트워크에서는 멀티캐스트가 제대로 수행되지 않는다.
 
#### Broadcast
- Broadcast는 일대 전부 통신(송신기 1대 수신기 전부)
- 모든 스테이션이 수신하고 처리할 수 있도록 하는 네트워크

#### 트래픽은 Input과 Output의 상호작용이다. 동일한 Input을 받더라도 Input의 종류 서버의 성능/ 개수, 치리코드 등에 따라 프로그램은 정상적으로 구동 할 수도, 장애가 발생할 수도 있다. 다양한 상황에서 Input을 받고 안정적으로 Output을 산출하기 위해 밣전한 I/O처리 모델

#### Blocking I/O
- Spring MVC와 RDBMS가 채택하고 있는 가장 기본 모델.
- Request이후 Respose를 받기 전까지 Application이 Block된다.
- 대부분의 JAVA 프로젝트에서 Blocking방식으로 설계되어있지만, 각 Input 마다 새로운 Thread가 할당되므로 속도의 저하를 체감할수 없다.
- 하지만 Thread pool을 초과하게 되면 Thread전환이 불가능하게 되므로 시스템성능이 급격히 저하됨
- 또한 I/O마다 Thread를 할당해야하는 Contet switching비용이 발생하므로 시스템 효율성을 보장하지 못한다
#### Synchronous Non blocking I/O
- Request 이루호 Return 되고 다른 작업을 수행하면서 Respose의 준비 여부를 체크해 Response를 처리한다. Response의 주기적 체크 방식을 Polling이라는 하는데 작업이 완료대기 전까지 지속적으로 호출하는 리소스를 사용해야 하므로 시스템 효율성이 떨어질 수 있다.
#### Asynchronous Non-blocking I/O
- Synchronous Non-Blocking I/O방식과 마찬가지로 Request 이후 즉시 Return 된다. 하지만 Polling방식과 다르게 Resposne이벤트가 발생하거나 미리 등록해 놓은 Callback을 통해 작업을 완료하므로 I/O과정에서 불필요한 대기 시간과 리소스 사용을 줄일 수 있다.

  



 
